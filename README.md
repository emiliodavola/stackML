# StackML - Revisi√≥n Final ‚úÖ

Un stack completo de MLOps con Docker Compose que incluye servicios para experimentaci√≥n, monitoreo, almacenamiento y desarrollo de modelos de machine learning.

## üöÄ Servicios Incluidos

### Servicios Principales (se levantan por defecto)

- **MLflow** (puerto 5000) - Tracking de experimentos y registro de modelos
- **MinIO** (puertos 9000/9001) - Almacenamiento de objetos compatible con S3
- **Marimo** (puerto 2718) - Notebooks interactivos modernos
- **Jupyter** (puerto 8888) - Notebooks tradicionales de Jupyter

### Servicios On-Demand (requieren perfil espec√≠fico)

- **Grafana** (puerto 3000) - Dashboards y visualizaci√≥n de m√©tricas
- **Prometheus** (puerto 9090) - Recolecci√≥n y almacenamiento de m√©tricas  
- **Elasticsearch** (puerto 9200) - B√∫squeda y an√°lisis de logs
- **API** (puerto 8000) - Servicio FastAPI para servir modelos

## üõ†Ô∏è Configuraci√≥n R√°pida

### Inicio R√°pido

1. **Clonar el repositorio:**

```bash
git clone <repository-url>
cd stackML
```

2. **Crear archivo de configuraci√≥n:**

Crea un archivo `.env` usando el template de la secci√≥n [Variables de Entorno](#variables-de-entorno-env).

3. **Levantar servicios b√°sicos:**

```bash
docker compose up -d
```

4. **Levantar todos los servicios (incluyendo on-demand):**

```bash
docker compose --profile on-demand up -d
```

5. **Acceder a los servicios:**

- MLflow: <http://localhost:5000>
- MinIO Console: <http://localhost:9001>
- Marimo: <http://localhost:2718>
- Jupyter: <http://localhost:8888>

**Solo con perfil on-demand:**

- Grafana: <http://localhost:3000>
- Prometheus: <http://localhost:9090>
- Elasticsearch: <http://localhost:9200>
- API: <http://localhost:8000>

## üìÅ Estructura del Proyecto

```
stackML/
‚îú‚îÄ‚îÄ api/                    # API FastAPI para servir modelos
‚îú‚îÄ‚îÄ config/                 # Configuraciones de servicios
‚îÇ   ‚îú‚îÄ‚îÄ grafana/           # Configuraci√≥n de Grafana
‚îÇ   ‚îî‚îÄ‚îÄ prometheus/        # Configuraci√≥n de Prometheus
‚îú‚îÄ‚îÄ data/                  # Vol√∫menes de datos persistentes
‚îú‚îÄ‚îÄ mlflow/                # Configuraci√≥n de MLflow
‚îú‚îÄ‚îÄ notebooks/             # Configuraci√≥n de notebooks
‚îÇ   ‚îú‚îÄ‚îÄ jupyter/           # Setup de Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ marimo/            # Setup de Marimo
‚îÇ   ‚îî‚îÄ‚îÄ work/              # Directorio compartido de trabajo
‚îî‚îÄ‚îÄ docker-compose.yml     # Configuraci√≥n principal
```

## üîß Configuraci√≥n

### Variables de Entorno (.env)

Las credenciales y configuraciones est√°n centralizadas en el archivo `.env`:

- **Puertos:** Configurables para todos los servicios
- **Credenciales:** Usuarios y contrase√±as por defecto
- **Versiones:** Im√°genes Docker espec√≠ficas para cada servicio

#### Template del archivo .env

Crea un archivo `.env` en la ra√≠z del proyecto con el siguiente contenido:

```bash
# Ports - Configuraci√≥n de puertos para cada servicio
MINIO_CONSOLE_PORT=9001
MINIO_PORT=9000
GRAFANA_PORT=3000
PROMETHEUS_PORT=9090
ELASTIC_PORT=9200

# Versions - Versiones de las im√°genes Docker
MINIO_IMAGE=minio/minio:latest
GRAFANA_IMAGE=grafana/grafana:latest
PROMETHEUS_IMAGE=prom/prometheus:latest
ELASTIC_IMAGE=elasticsearch:8.8.0

# Credentials - Usuarios y contrase√±as (¬°CAMBIAR EN PRODUCCI√ìN!)
MINIO_ROOT_USER=minio
MINIO_ROOT_PASSWORD=minioadmin123
ELASTIC_USERNAME=elastic
ELASTIC_PASSWORD=elasticadmin123
GF_SECURITY_ADMIN_USER=grafana
GF_SECURITY_ADMIN_PASSWORD=grafanaadmin123
JUPYTER_PASSWORD=jupyteradmin123
MARIMO_PASSWORD=marimoadmin123

# Compose - Configuraci√≥n de Docker Compose
COMPOSE_PROJECT_NAME=stackml
```

> ‚ö†Ô∏è **Importante**: Cambia todas las contrase√±as antes de usar en producci√≥n.

### Datos Persistentes

Todos los datos se almacenan en la carpeta `data/` y persisten entre reinicios:

- `data/mlflow/` - Experimentos y modelos de MLflow
- `data/grafana/` - Dashboards y configuraciones
- `data/elasticsearch/` - √çndices y datos
- `data/minio/` - Objetos almacenados
- `data/prometheus/` - M√©tricas hist√≥ricas
- `notebooks/work/` - Notebooks compartidos

### Perfiles de Docker Compose

El proyecto utiliza perfiles para optimizar el uso de recursos:

- **Por defecto**: Solo servicios esenciales (MLflow, MinIO, Marimo, Jupyter)
- **Perfil `on-demand`**: Servicios adicionales de monitoreo e inferencia

```bash
# Solo servicios b√°sicos
docker compose up -d

# Todos los servicios
docker compose --profile on-demand up -d
```

## üîÑ Comandos √ötiles

```bash
# Levantar solo servicios b√°sicos
docker compose up -d

# Levantar todos los servicios (incluyendo on-demand)
docker compose --profile on-demand up -d

# Ver logs de un servicio espec√≠fico
docker compose logs -f mlflow

# Detener todos los servicios
docker compose down

# Rebuild y levantar
docker compose up --build -d

# Rebuild con perfil on-demand
docker compose --profile on-demand up --build -d

# Ver estado de los contenedores
docker compose ps
```

## üõ°Ô∏è Seguridad

- **Elasticsearch** configurado con autenticaci√≥n b√°sica (user: `elastic`)
- **Grafana** con usuario administrador configurado (user: `grafana`)
- **MinIO** con credenciales personalizables (user: `minio`)
- **Jupyter** protegido con token de acceso
- **Marimo** protegido con contrase√±a
- Red interna Docker para comunicaci√≥n entre servicios
- Todas las credenciales configurables via archivo `.env`

## üìä Monitoreo

- **Prometheus** recolecta m√©tricas de sistema y aplicaciones
- **Grafana** proporciona dashboards para visualizaci√≥n
- **Elasticsearch** almacena logs para an√°lisis

## üß™ Desarrollo

### Notebooks

- **Marimo**: Notebooks reactivos y modernos (recomendado)
- **Jupyter**: Notebooks tradicionales para compatibilidad

### MLflow

- Tracking autom√°tico de experimentos
- Registro de modelos centralizado
- UI web para exploraci√≥n

### API

- FastAPI para deployment de modelos
- Integraci√≥n con MLflow Model Registry
- Escalable y documentaci√≥n autom√°tica

## üöÄ Pr√≥ximos Pasos

- [ ] Dashboards predefinidos en Grafana
- [ ] Configuraci√≥n de alertas en Prometheus
- [ ] Pipeline CI/CD para modelos
- [ ] Integraci√≥n con herramientas de feature store
- [ ] Configuraci√≥n de backup autom√°tico

## üìù Contribuci√≥n

1. Fork el proyecto
2. Crear una branch para tu feature (`git checkout -b feature/nueva-feature`)
3. Commit tus cambios (`git commit -am 'Agregar nueva feature'`)
4. Push a la branch (`git push origin feature/nueva-feature`)
5. Crear un Pull Request

## ü§ñ Desarrollo Asistido

Este proyecto fue desarrollado con la asistencia de **Claude 4 Sonnet** (Anthropic), que ayud√≥ en:

- üèóÔ∏è **Arquitectura del stack**: Dise√±o de la estructura de servicios MLOps
- ‚öôÔ∏è **Configuraci√≥n de Docker**: Optimizaci√≥n de Dockerfiles y docker-compose
- üì¶ **Gesti√≥n de dependencias**: Organizaci√≥n y actualizaci√≥n de requirements
- üîß **Perfiles on-demand**: Implementaci√≥n del sistema de contenedores din√°micos
- üìö **Documentaci√≥n**: Redacci√≥n de README y mejores pr√°cticas
- üõ°Ô∏è **Seguridad**: Configuraci√≥n de autenticaci√≥n y variables de entorno

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Ver `LICENSE` para m√°s detalles.
